{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1hxJuAlR4kj0lMB8cp6mjnB-3kQD8JylX",
      "authorship_tag": "ABX9TyM2HpY/aerXqBnqmXNXBOnR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Linkanblomman/Fight_recognition/blob/master/test_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjAdZRoH4UZg",
        "colab_type": "text"
      },
      "source": [
        "If no video output. Reset Colab notebook and run again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEbezk_MgDAO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_architecture = 50 # ResNet-34\n",
        "dataset='K' # Kinetics-700\n",
        "video = \"test\" # In folder \"./fight_recognition/input/test_data/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LZR2o_WPNw6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Change \"/content/drive/My Drive/Colab_Notebooks/fight_recognition/\" to your own Google Drive path\n",
        "!ln -s \"/content/drive/My Drive/Colab_Notebooks/fight_recognition/\" /content/fight_recognition"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5Jsxf2jOOYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import joblib\n",
        "import cv2\n",
        "import time\n",
        "import math\n",
        " \n",
        "from PIL import Image\n",
        "\n",
        "import fight_recognition.model as ResNet\n",
        "from fight_recognition.spatial_transforms import (Compose, Normalize, Resize, CenterCrop,\n",
        "                                CornerCrop, MultiScaleCornerCrop,\n",
        "                                RandomResizedCrop, RandomHorizontalFlip,\n",
        "                                ToTensor, ScaleValue, ColorJitter,\n",
        "                                PickFirstChannels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf1TmP7hQ_tV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVbkZ6RUPXWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the trained model and label binarizer from disk\n",
        "print('Loading model and label binarizer...')\n",
        "lb = joblib.load(\"./fight_recognition/outputs/lb.pkl\")\n",
        "\n",
        "model = ResNet.initialize_model(model_architecture=model_architecture, model_dataset=dataset, num_classes=2)\n",
        "print('Model Loaded...')\n",
        "\n",
        "model.load_state_dict(torch.load(\"./fight_recognition/outputs/fight_reco_3DCNNmodel.pth\"))\n",
        "print('Loaded model state_dict...')\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "model.to(device)\n",
        "\n",
        "if (dataset == 'K'):\n",
        "  mean = [0.4345, 0.4051, 0.3775]\n",
        "  std = [0.2768, 0.2713, 0.2737]\n",
        "else:\n",
        "  mean = [0.5, 0.5, 0.5]\n",
        "  std = [0.5, 0.5, 0.5]\n",
        "\n",
        "sample_size = 112 # resolution of frame\n",
        "\n",
        "spatial_transform =  Compose([Resize(sample_size),\n",
        "                                        CenterCrop(sample_size),\n",
        "                                        ToTensor(),\n",
        "                                        Normalize(mean, std)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvT-HAWsPgvc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VIDEO_PATH = \"./fight_recognition/input/test_data/\" + video + \".mp4\"\n",
        "\n",
        "cap = cv2.VideoCapture(VIDEO_PATH)\n",
        "\n",
        "if (cap.isOpened() == False):\n",
        "    print('Error while trying to read video. Plese check again...')\n",
        "\n",
        "# get the frame width and height\n",
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))\n",
        "\n",
        "collected_frames = []\n",
        "\n",
        "# read until end of video\n",
        "while(cap.isOpened()):\n",
        "    # capture each frame of the video\n",
        "    ret, frame = cap.read() # capturing the frame \n",
        "    if ret == True:\n",
        "        pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "        collected_frames.append(pil_image)     \n",
        "    else:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "          duration = len(collected_frames)\n",
        "          frames = 16\n",
        "          steps = math.floor(duration/frames)\n",
        "          start_frame = 0\n",
        "          stop_frame = steps * frames\n",
        "          \n",
        "          frame_id_list = range(start_frame, stop_frame, steps)\n",
        "          collected_frames = [collected_frames[id] for id in frame_id_list]\n",
        "\n",
        "          video_snippet = [spatial_transform(frame) for frame in collected_frames]\n",
        "          video_snippet = torch.stack(video_snippet, 0).permute(1,0,2,3) # [Channel, Depth, Height, Width]\n",
        "\n",
        "          batch = video_snippet.unsqueeze(0).cuda() # [Batch, Channel, Depth, Height, Width]\n",
        "          print(\"Batch shape:\", batch.shape)\n",
        "          \n",
        "          outputs = model(batch)\n",
        "          _, preds = torch.max(outputs.data, 1)\n",
        "          \n",
        "          prediction = lb.classes_[preds]\n",
        "          print(\"Model predict:\",prediction)\n",
        "        break  \n",
        "\n",
        "# release VideoCapture()\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "si9U6g26PlJ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cap = cv2.VideoCapture(VIDEO_PATH)\n",
        "\n",
        "if (cap.isOpened() == False):\n",
        "    print('Error while trying to read video. Plese check again...')\n",
        "\n",
        "# get the frame width and height\n",
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))\n",
        "\n",
        "image_text_pos_X = int(frame_width/2.5)\n",
        "image_text_pos_Y = int(frame_height/10)\n",
        "\n",
        "# define codec and create VideoWriter object (specify the format for saving the video)\n",
        "out = cv2.VideoWriter(str(\"./fight_recognition/outputs/model_prediction_on_video/\" + prediction + \"_\" + video + \".mp4\"), cv2.VideoWriter_fourcc(*'mp4v'), 30, (frame_width,frame_height))\n",
        "\n",
        "while(cap.isOpened()):\n",
        "    # capture each frame of the video\n",
        "    ret, frame = cap.read() # capturing the frame \n",
        "    if ret == True:\n",
        "        cv2.rectangle(frame, (int(image_text_pos_X - 50), int(image_text_pos_Y - 30)) , (int(image_text_pos_X + 160), int(image_text_pos_Y + 10)), (96,96,96), -1)\n",
        "        #image, text, pos, font, fontSize, fontColor, fontThickness\n",
        "        if(prediction == \"fight\"):\n",
        "            cv2.putText(frame, lb.classes_[preds], (int(image_text_pos_X + 20), image_text_pos_Y), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2) \n",
        "        else:\n",
        "            cv2.putText(frame, lb.classes_[preds], (int(image_text_pos_X), image_text_pos_Y), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
        "        out.write(frame)\n",
        "    else: \n",
        "        break\n",
        "\n",
        "# release VideoCapture()\n",
        "cap.release()\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "print(\"Model prediction COMPLETE\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}