{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "github_train_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1BfaTQ9kxHjn2UawQ2e9M4uqAn400HjFx",
      "authorship_tag": "ABX9TyMCgiKSlJjFZZ3scPT9ui/L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Linkanblomman/Fight_recognition/blob/master/github_train_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzuZ9cegsPqE",
        "colab_type": "text"
      },
      "source": [
        "Connect to seperate folder that have been loaded into Google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb-lp7DksEmD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a6d8782b-d278-4144-9942-96e81ed5c746"
      },
      "source": [
        "!ln -s \"/content/drive/My Drive/Colab_Notebooks/fight_recognition/\" /content/fight_recognition"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ln: failed to create symbolic link '/content/fight_recognition/fight_recognition': Operation not supported\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRyHM9vBt3qV",
        "colab_type": "text"
      },
      "source": [
        "Install decord for video slicing (https://github.com/dmlc/decord)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1Qh93L9sqG-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9320b098-b7e8-4228-c0a7-2855c5f36092"
      },
      "source": [
        "!pip install decord"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: decord in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from decord) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtbkeJhXskQX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import math\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.style.use('ggplot')\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from decord import VideoReader\n",
        "from decord import bridge\n",
        "#from decord import cpu, gpu\n",
        "\n",
        "from fight_recognition.SGDR import CosineAnnealingLR_with_Restart\n",
        "\n",
        "import fight_recognition.model as ResNet\n",
        "from fight_recognition.spatial_transforms import (Compose, Normalize, Resize, CenterCrop,\n",
        "                                CornerCrop, MultiScaleCornerCrop,\n",
        "                                RandomResizedCrop, RandomHorizontalFlip,\n",
        "                                ToTensor, ScaleValue, ColorJitter,\n",
        "                                PickFirstChannels)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xohgHRR5Y7OO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "799e5691-1a3f-46be-cb8e-7c0d045a1f63"
      },
      "source": [
        "seed_value = 42\n",
        "torch.manual_seed(seed_value)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f27e9c741b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzCca4qO4tLo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "796cee15-b931-4ccf-9c0f-09d6592b934f"
      },
      "source": [
        "print(torch.cuda.device_count())\n",
        "print(torch.cuda.get_device_name(0))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7RCrM5yuL5C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ef451f51-a820-4ad8-9183-9b859377fe63"
      },
      "source": [
        "batch_size = 16\n",
        "model_architecture = 34 # Generate resnet model\n",
        "\n",
        "# K - Kinetics-700\n",
        "# KM - Kinetics-700 and Moments in Time\n",
        "dataset = 'K'\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "print(f\"Computation device: {device}\\n\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computation device: cuda:0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gg8kdA8QuMfk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "908580c0-8869-4a30-b376-d856939bdee1"
      },
      "source": [
        "# read the data.csv file and get the video paths and labels\n",
        "df = pd.read_csv('./fight_recognition/input/data.csv')\n",
        "X = df.video_path.values # video paths\n",
        "y = df.target.values # targets\n",
        "\n",
        "(xtrain, xtest, ytrain, ytest) = train_test_split(X, y, test_size=0.20, random_state=seed_value)\n",
        "\n",
        "print(f\"Training videos: {len(xtrain)}\")\n",
        "print(f\"Training labels: {len(ytrain)}\\n\")\n",
        "\n",
        "print(f\"Validation videos: {len(xtest)}\")\n",
        "print(f\"Validation labels: {len(ytest)}\\n\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training videos: 240\n",
            "Training labels: 240\n",
            "\n",
            "Validation videos: 60\n",
            "Validation labels: 60\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuWd9Sy7uko-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# custom dataset\n",
        "class VideoDataset(Dataset):\n",
        "    def __init__(self, videos, labels=None, spatial_transform=None):\n",
        "        self.X = videos\n",
        "        self.y = labels\n",
        "        self.spatial_transform = spatial_transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return (len(self.X))\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        vr = VideoReader(self.X[i]) # Read video\n",
        "        bridge.set_bridge('native')\n",
        "        duration = len(vr)\n",
        "        frames = 16\n",
        "        steps = math.floor(duration/frames)\n",
        "        start_frame = 0\n",
        "        stop_frame = steps * frames\n",
        "        \n",
        "        frame_id_list = range(start_frame, stop_frame, steps) \n",
        "        \n",
        "        clip = []\n",
        "        video_snippet = vr.get_batch(frame_id_list).asnumpy() # Will get a batch of 16 frames from video\n",
        "\n",
        "        # Transform into images\n",
        "        for img in video_snippet:\n",
        "            im_pil = Image.fromarray(img)\n",
        "            clip.append(im_pil)\n",
        "            #plt.imshow(im_pil)\n",
        "            #plt.show()\n",
        "\n",
        "        if self.spatial_transform is not None:\n",
        "            clip = [self.spatial_transform(img) for img in clip]\n",
        "\n",
        "        clip = torch.stack(clip, 0).permute(1, 0, 2, 3)\n",
        "   \n",
        "        label = self.y[i]\n",
        "        \n",
        "        return (clip.clone().detach().requires_grad_(True), torch.tensor(label, dtype=torch.long))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YjsoeCQ4sk2",
        "colab_type": "text"
      },
      "source": [
        "Trying to copy the data augmentation  step from https://github.com/kenshohara/3D-ResNets-PyTorch/blob/master/main.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZN1FGJjku1hY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if (dataset == 'K'):\n",
        "  mean = [0.4345, 0.4051, 0.3775]\n",
        "  std = [0.2768, 0.2713, 0.2737]\n",
        "else:\n",
        "  mean = [0.5, 0.5, 0.5]\n",
        "  std = [0.5, 0.5, 0.5]\n",
        "\n",
        "sample_size = 112 # resolution of frame\n",
        "\n",
        "# MultiScaleCornerCrop (four-corner cropping)\n",
        "scales = [1.0]\n",
        "scale_step = 1 / (2**(1 / 4))\n",
        "for _ in range(1, 5):\n",
        "    scales.append(scales[-1] * scale_step)\n",
        "\n",
        "spatial_transform_train = Compose([\n",
        "                                   MultiScaleCornerCrop(sample_size, scales),\n",
        "                                   RandomHorizontalFlip(),\n",
        "                                   ToTensor(),\n",
        "                                   Normalize(mean, std)\n",
        "                                   ])\n",
        "\n",
        "spatial_transform_validation =  Compose([Resize(sample_size),\n",
        "                                        CenterCrop(sample_size),\n",
        "                                        ToTensor(),\n",
        "                                        Normalize(mean, std)])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR7kaF6QvJfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = VideoDataset(xtrain, ytrain, spatial_transform_train)\n",
        "test_data = VideoDataset(xtest, ytest, spatial_transform_validation)\n",
        "\n",
        "TrainLoader = DataLoader(train_data, batch_size=batch_size, shuffle=True) # If shuffle is set to True, it will have the data reshuffled at every epoch\n",
        "TestLoader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMt6tGP6vgq1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "4fec32a0-2b9b-409e-b66f-7c115c13968c"
      },
      "source": [
        "model = ResNet.initialize_model(model_architecture=model_architecture, model_dataset=dataset, num_classes=2)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: ResNet34\n",
            "Dataset: Kinetics-700\n",
            "\n",
            "Model parameters\n",
            "Learning rate: 3.0000000000000012e-09\n",
            "Momentum: 0.9\n",
            "Weight_decay: 0.0001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMQxf76CLX3v",
        "colab_type": "text"
      },
      "source": [
        "Load pre-trained model (https://github.com/kenshohara/3D-ResNets-PyTorch)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeYGBOIKwlm2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "c6920234-0a24-4aeb-9159-647320671c38"
      },
      "source": [
        "for name, child in model.named_children():\n",
        "    if name in ['layer4','fc']: # Layer that will be unfrozen\n",
        "        print(name + ' is unfrozen')\n",
        "        for param in child.parameters():\n",
        "            param.requires_grad = True\n",
        "    else:\n",
        "        print(name + ' is frozen')\n",
        "        for param in child.parameters():\n",
        "            param.requires_grad = False  \n",
        "\n",
        "model.to(device)\n",
        "\n",
        "optimizer = optim.SGD([{'params': model.layer4.parameters()}, \n",
        "                      {'params': model.fc.parameters(), 'lr': 3e-3}\n",
        "                       ], lr=3e-05,momentum=.9, weight_decay=.0001)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# SGDR\n",
        "t_mult = 1 # cycle multiplication\n",
        "t_max = 25 # Maximum number of iterations/epochs\n",
        "scheduler = CosineAnnealingLR_with_Restart(optimizer, T_max=t_max, T_mult=t_mult, model=model, out_dir='./fight_recognition/outputs/snapshots/', take_snapshot=True, eta_min=3e-09) # eta_min – Minimum learning rate"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1 is frozen\n",
            "bn1 is frozen\n",
            "relu is frozen\n",
            "maxpool is frozen\n",
            "layer1 is frozen\n",
            "layer2 is frozen\n",
            "layer3 is frozen\n",
            "layer4 is unfrozen\n",
            "avgpool is frozen\n",
            "fc is unfrozen\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BNBrCdBB3jT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b0c08985-b62e-4cfe-c6dd-65cb39eb5be6"
      },
      "source": [
        "# learning rate for each layer\n",
        "for param_group in optimizer.param_groups:\n",
        "    print(param_group['lr'])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3e-05\n",
            "0.003\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UG9mEKVq_1dg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "100d9e07-1cc6-4dcb-db39-829581c06902"
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv3d(3, 64, kernel_size=(7, 7, 7), stride=(1, 2, 2), padding=(3, 3, 3), bias=False)\n",
              "  (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool3d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
              "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
              "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
              "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
              "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (4): BasicBlock(\n",
              "      (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (5): BasicBlock(\n",
              "      (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
              "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
              "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwmUW2ED3Jmi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9e986d4a-e725-465a-bbc8-b2b170120056"
      },
      "source": [
        "for n, p in model.named_parameters():\n",
        "  print(p.device, \" \", n)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0   conv1.weight\n",
            "cuda:0   bn1.weight\n",
            "cuda:0   bn1.bias\n",
            "cuda:0   layer1.0.conv1.weight\n",
            "cuda:0   layer1.0.bn1.weight\n",
            "cuda:0   layer1.0.bn1.bias\n",
            "cuda:0   layer1.0.conv2.weight\n",
            "cuda:0   layer1.0.bn2.weight\n",
            "cuda:0   layer1.0.bn2.bias\n",
            "cuda:0   layer1.1.conv1.weight\n",
            "cuda:0   layer1.1.bn1.weight\n",
            "cuda:0   layer1.1.bn1.bias\n",
            "cuda:0   layer1.1.conv2.weight\n",
            "cuda:0   layer1.1.bn2.weight\n",
            "cuda:0   layer1.1.bn2.bias\n",
            "cuda:0   layer1.2.conv1.weight\n",
            "cuda:0   layer1.2.bn1.weight\n",
            "cuda:0   layer1.2.bn1.bias\n",
            "cuda:0   layer1.2.conv2.weight\n",
            "cuda:0   layer1.2.bn2.weight\n",
            "cuda:0   layer1.2.bn2.bias\n",
            "cuda:0   layer2.0.conv1.weight\n",
            "cuda:0   layer2.0.bn1.weight\n",
            "cuda:0   layer2.0.bn1.bias\n",
            "cuda:0   layer2.0.conv2.weight\n",
            "cuda:0   layer2.0.bn2.weight\n",
            "cuda:0   layer2.0.bn2.bias\n",
            "cuda:0   layer2.0.downsample.0.weight\n",
            "cuda:0   layer2.0.downsample.1.weight\n",
            "cuda:0   layer2.0.downsample.1.bias\n",
            "cuda:0   layer2.1.conv1.weight\n",
            "cuda:0   layer2.1.bn1.weight\n",
            "cuda:0   layer2.1.bn1.bias\n",
            "cuda:0   layer2.1.conv2.weight\n",
            "cuda:0   layer2.1.bn2.weight\n",
            "cuda:0   layer2.1.bn2.bias\n",
            "cuda:0   layer2.2.conv1.weight\n",
            "cuda:0   layer2.2.bn1.weight\n",
            "cuda:0   layer2.2.bn1.bias\n",
            "cuda:0   layer2.2.conv2.weight\n",
            "cuda:0   layer2.2.bn2.weight\n",
            "cuda:0   layer2.2.bn2.bias\n",
            "cuda:0   layer2.3.conv1.weight\n",
            "cuda:0   layer2.3.bn1.weight\n",
            "cuda:0   layer2.3.bn1.bias\n",
            "cuda:0   layer2.3.conv2.weight\n",
            "cuda:0   layer2.3.bn2.weight\n",
            "cuda:0   layer2.3.bn2.bias\n",
            "cuda:0   layer3.0.conv1.weight\n",
            "cuda:0   layer3.0.bn1.weight\n",
            "cuda:0   layer3.0.bn1.bias\n",
            "cuda:0   layer3.0.conv2.weight\n",
            "cuda:0   layer3.0.bn2.weight\n",
            "cuda:0   layer3.0.bn2.bias\n",
            "cuda:0   layer3.0.downsample.0.weight\n",
            "cuda:0   layer3.0.downsample.1.weight\n",
            "cuda:0   layer3.0.downsample.1.bias\n",
            "cuda:0   layer3.1.conv1.weight\n",
            "cuda:0   layer3.1.bn1.weight\n",
            "cuda:0   layer3.1.bn1.bias\n",
            "cuda:0   layer3.1.conv2.weight\n",
            "cuda:0   layer3.1.bn2.weight\n",
            "cuda:0   layer3.1.bn2.bias\n",
            "cuda:0   layer3.2.conv1.weight\n",
            "cuda:0   layer3.2.bn1.weight\n",
            "cuda:0   layer3.2.bn1.bias\n",
            "cuda:0   layer3.2.conv2.weight\n",
            "cuda:0   layer3.2.bn2.weight\n",
            "cuda:0   layer3.2.bn2.bias\n",
            "cuda:0   layer3.3.conv1.weight\n",
            "cuda:0   layer3.3.bn1.weight\n",
            "cuda:0   layer3.3.bn1.bias\n",
            "cuda:0   layer3.3.conv2.weight\n",
            "cuda:0   layer3.3.bn2.weight\n",
            "cuda:0   layer3.3.bn2.bias\n",
            "cuda:0   layer3.4.conv1.weight\n",
            "cuda:0   layer3.4.bn1.weight\n",
            "cuda:0   layer3.4.bn1.bias\n",
            "cuda:0   layer3.4.conv2.weight\n",
            "cuda:0   layer3.4.bn2.weight\n",
            "cuda:0   layer3.4.bn2.bias\n",
            "cuda:0   layer3.5.conv1.weight\n",
            "cuda:0   layer3.5.bn1.weight\n",
            "cuda:0   layer3.5.bn1.bias\n",
            "cuda:0   layer3.5.conv2.weight\n",
            "cuda:0   layer3.5.bn2.weight\n",
            "cuda:0   layer3.5.bn2.bias\n",
            "cuda:0   layer4.0.conv1.weight\n",
            "cuda:0   layer4.0.bn1.weight\n",
            "cuda:0   layer4.0.bn1.bias\n",
            "cuda:0   layer4.0.conv2.weight\n",
            "cuda:0   layer4.0.bn2.weight\n",
            "cuda:0   layer4.0.bn2.bias\n",
            "cuda:0   layer4.0.downsample.0.weight\n",
            "cuda:0   layer4.0.downsample.1.weight\n",
            "cuda:0   layer4.0.downsample.1.bias\n",
            "cuda:0   layer4.1.conv1.weight\n",
            "cuda:0   layer4.1.bn1.weight\n",
            "cuda:0   layer4.1.bn1.bias\n",
            "cuda:0   layer4.1.conv2.weight\n",
            "cuda:0   layer4.1.bn2.weight\n",
            "cuda:0   layer4.1.bn2.bias\n",
            "cuda:0   layer4.2.conv1.weight\n",
            "cuda:0   layer4.2.bn1.weight\n",
            "cuda:0   layer4.2.bn1.bias\n",
            "cuda:0   layer4.2.conv2.weight\n",
            "cuda:0   layer4.2.bn2.weight\n",
            "cuda:0   layer4.2.bn2.bias\n",
            "cuda:0   fc.weight\n",
            "cuda:0   fc.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9B49zrcFx0d1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3224a895-e472-4b2d-dfd8-58398dfd4c11"
      },
      "source": [
        "print(\"Check model requires_grad params\\n\")\n",
        "print(\"Status\\tParameters\\n\")\n",
        "for n, p in model.named_parameters():\n",
        "    print(p.requires_grad, \" \", n)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Check model requires_grad params\n",
            "\n",
            "Status\tParameters\n",
            "\n",
            "False   conv1.weight\n",
            "False   bn1.weight\n",
            "False   bn1.bias\n",
            "False   layer1.0.conv1.weight\n",
            "False   layer1.0.bn1.weight\n",
            "False   layer1.0.bn1.bias\n",
            "False   layer1.0.conv2.weight\n",
            "False   layer1.0.bn2.weight\n",
            "False   layer1.0.bn2.bias\n",
            "False   layer1.1.conv1.weight\n",
            "False   layer1.1.bn1.weight\n",
            "False   layer1.1.bn1.bias\n",
            "False   layer1.1.conv2.weight\n",
            "False   layer1.1.bn2.weight\n",
            "False   layer1.1.bn2.bias\n",
            "False   layer1.2.conv1.weight\n",
            "False   layer1.2.bn1.weight\n",
            "False   layer1.2.bn1.bias\n",
            "False   layer1.2.conv2.weight\n",
            "False   layer1.2.bn2.weight\n",
            "False   layer1.2.bn2.bias\n",
            "False   layer2.0.conv1.weight\n",
            "False   layer2.0.bn1.weight\n",
            "False   layer2.0.bn1.bias\n",
            "False   layer2.0.conv2.weight\n",
            "False   layer2.0.bn2.weight\n",
            "False   layer2.0.bn2.bias\n",
            "False   layer2.0.downsample.0.weight\n",
            "False   layer2.0.downsample.1.weight\n",
            "False   layer2.0.downsample.1.bias\n",
            "False   layer2.1.conv1.weight\n",
            "False   layer2.1.bn1.weight\n",
            "False   layer2.1.bn1.bias\n",
            "False   layer2.1.conv2.weight\n",
            "False   layer2.1.bn2.weight\n",
            "False   layer2.1.bn2.bias\n",
            "False   layer2.2.conv1.weight\n",
            "False   layer2.2.bn1.weight\n",
            "False   layer2.2.bn1.bias\n",
            "False   layer2.2.conv2.weight\n",
            "False   layer2.2.bn2.weight\n",
            "False   layer2.2.bn2.bias\n",
            "False   layer2.3.conv1.weight\n",
            "False   layer2.3.bn1.weight\n",
            "False   layer2.3.bn1.bias\n",
            "False   layer2.3.conv2.weight\n",
            "False   layer2.3.bn2.weight\n",
            "False   layer2.3.bn2.bias\n",
            "False   layer3.0.conv1.weight\n",
            "False   layer3.0.bn1.weight\n",
            "False   layer3.0.bn1.bias\n",
            "False   layer3.0.conv2.weight\n",
            "False   layer3.0.bn2.weight\n",
            "False   layer3.0.bn2.bias\n",
            "False   layer3.0.downsample.0.weight\n",
            "False   layer3.0.downsample.1.weight\n",
            "False   layer3.0.downsample.1.bias\n",
            "False   layer3.1.conv1.weight\n",
            "False   layer3.1.bn1.weight\n",
            "False   layer3.1.bn1.bias\n",
            "False   layer3.1.conv2.weight\n",
            "False   layer3.1.bn2.weight\n",
            "False   layer3.1.bn2.bias\n",
            "False   layer3.2.conv1.weight\n",
            "False   layer3.2.bn1.weight\n",
            "False   layer3.2.bn1.bias\n",
            "False   layer3.2.conv2.weight\n",
            "False   layer3.2.bn2.weight\n",
            "False   layer3.2.bn2.bias\n",
            "False   layer3.3.conv1.weight\n",
            "False   layer3.3.bn1.weight\n",
            "False   layer3.3.bn1.bias\n",
            "False   layer3.3.conv2.weight\n",
            "False   layer3.3.bn2.weight\n",
            "False   layer3.3.bn2.bias\n",
            "False   layer3.4.conv1.weight\n",
            "False   layer3.4.bn1.weight\n",
            "False   layer3.4.bn1.bias\n",
            "False   layer3.4.conv2.weight\n",
            "False   layer3.4.bn2.weight\n",
            "False   layer3.4.bn2.bias\n",
            "False   layer3.5.conv1.weight\n",
            "False   layer3.5.bn1.weight\n",
            "False   layer3.5.bn1.bias\n",
            "False   layer3.5.conv2.weight\n",
            "False   layer3.5.bn2.weight\n",
            "False   layer3.5.bn2.bias\n",
            "True   layer4.0.conv1.weight\n",
            "True   layer4.0.bn1.weight\n",
            "True   layer4.0.bn1.bias\n",
            "True   layer4.0.conv2.weight\n",
            "True   layer4.0.bn2.weight\n",
            "True   layer4.0.bn2.bias\n",
            "True   layer4.0.downsample.0.weight\n",
            "True   layer4.0.downsample.1.weight\n",
            "True   layer4.0.downsample.1.bias\n",
            "True   layer4.1.conv1.weight\n",
            "True   layer4.1.bn1.weight\n",
            "True   layer4.1.bn1.bias\n",
            "True   layer4.1.conv2.weight\n",
            "True   layer4.1.bn2.weight\n",
            "True   layer4.1.bn2.bias\n",
            "True   layer4.2.conv1.weight\n",
            "True   layer4.2.bn1.weight\n",
            "True   layer4.2.bn1.bias\n",
            "True   layer4.2.conv2.weight\n",
            "True   layer4.2.bn2.weight\n",
            "True   layer4.2.bn2.bias\n",
            "True   fc.weight\n",
            "True   fc.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4pYVa-5yBLN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5289d92d-c7c2-45db-e038-d13596913b76"
      },
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"{total_params:,} total parameters.\")\n",
        "total_trainable_params = sum(\n",
        "    p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"{total_trainable_params:,} training parameters.\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63,514,562 total parameters.\n",
            "39,067,650 training parameters.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYpESWIFyEPA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training function\n",
        "def fit(model, train_dataloader):\n",
        "    print('Training')\n",
        "    model.train() # training mode activated if no_grad() have deactivate the gradient calculation part in validation function\n",
        "    train_running_loss = 0.0\n",
        "    train_running_correct = 0\n",
        "    for i, data in tqdm(enumerate(train_dataloader), total=int(len(train_data)/train_dataloader.batch_size)):\n",
        "        data, target = data[0].to(device), data[1].to(device) \n",
        "        optimizer.zero_grad() # Reset optimizer to zero otherwise it will just accumulate all the gradients\n",
        "        outputs = model(data) # Input the bathed images to the model to get a output (prediction)\n",
        "        \n",
        "        # From the loss function we will get back a loss tensor. PyTorch have the computaional graph for the tensor that will be used in the backpropagation step \n",
        "        loss = criterion(outputs, target) # calculate the loss from the loss/error function (prediction_label - true_label)\n",
        "        train_running_loss += loss.item() # new loss value to update the current training loss value\n",
        "        _, preds = torch.max(input=outputs.data, dim=1) # Returns the maximum value of all elements in the input tensor\n",
        "        train_running_correct += (preds == target).sum().item() # Count the right numbers of correct prediction\n",
        "        loss.backward() # Calculate gradients\n",
        "        optimizer.step() # Update the weights\n",
        "        \n",
        "    train_loss = train_running_loss/len(train_dataloader.dataset)\n",
        "    train_accuracy = 100. * train_running_correct/len(train_dataloader.dataset)\n",
        "    \n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}\")\n",
        "    \n",
        "    return train_loss, train_accuracy"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkMXeuejyF8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#validation function\n",
        "def validate(model, test_dataloader):\n",
        "    print('Validating')\n",
        "    model.eval()\n",
        "    val_running_loss = 0.0\n",
        "    val_running_correct = 0\n",
        "    with torch.no_grad():\n",
        "        for i, data in tqdm(enumerate(test_dataloader), total=int(len(test_data)/test_dataloader.batch_size)):\n",
        "            data, target = data[0].to(device), data[1].to(device)\n",
        "            outputs = model(data)\n",
        "            loss = criterion(outputs, target)\n",
        "            \n",
        "            val_running_loss += loss.item()\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            val_running_correct += (preds == target).sum().item()\n",
        "        \n",
        "        val_loss = val_running_loss/len(test_dataloader.dataset)\n",
        "        val_accuracy = 100. * val_running_correct/len(test_dataloader.dataset)\n",
        "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}')\n",
        "        \n",
        "        return val_loss, val_accuracy"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4XWmsyeyIsA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "33bf9945-28b6-4cc1-cbe4-479d54d54fb2"
      },
      "source": [
        "train_loss , train_accuracy = [], []\n",
        "val_loss , val_accuracy = [], []\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "start = time.time()\n",
        "for epoch in range(epochs):\n",
        "    scheduler.step() # SGDR\n",
        "    print(f\"Epoch {epoch+1} of {epochs}\")\n",
        "    train_epoch_loss, train_epoch_accuracy = fit(model, TrainLoader)\n",
        "    val_epoch_loss, val_epoch_accuracy = validate(model, TestLoader)\n",
        "    train_loss.append(train_epoch_loss)\n",
        "    train_accuracy.append(train_epoch_accuracy)\n",
        "    val_loss.append(val_epoch_loss)\n",
        "    val_accuracy.append(val_epoch_accuracy)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"{(end-start)/60:.3f} minutes\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/15 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 of 100\n",
            "Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 2/15 [00:29<03:22, 15.55s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-a03068c1d64b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# SGDR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1} of {epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_epoch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_epoch_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mval_epoch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_epoch_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTestLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_epoch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-f020ea3b4e5f>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, train_dataloader)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_running_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtrain_running_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Reset optimizer to zero otherwise it will just accumulate all the gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-6a23ca6ba485>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mvr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVideoReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Read video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mbridge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_bridge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'native'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/decord/video_reader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, uri, ctx, width, height, num_threads)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             self._handle = _CAPI_VideoReaderGetVideoReader(\n\u001b[0;32m---> 45\u001b[0;31m                 uri, ctx.device_type, ctx.device_id, width, height, num_threads, 0)\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error reading \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0muri\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/decord/_ffi/_ctypes/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    173\u001b[0m         check_call(_LIB.DECORDFuncCall(\n\u001b[1;32m    174\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             ctypes.byref(ret_val), ctypes.byref(ret_tcode)))\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEXGpIr1yL6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# accuracy plots\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(train_accuracy, color='green', label='train accuracy')\n",
        "plt.plot(val_accuracy, color='blue', label='validataion accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.savefig('./fight_recognition/outputs/accuracy_3DCNN.png')\n",
        "plt.show()\n",
        "\n",
        "# loss plots\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(train_loss, color='orange', label='train loss')\n",
        "plt.plot(val_loss, color='red', label='validataion loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.savefig('./fight_recognition/outputs/loss_3DCNN.png')\n",
        "plt.show()\n",
        "\n",
        "# serialize the model to disk\n",
        "print('Saving model...')\n",
        "torch.save(model.state_dict(), \"./fight_recognition/outputs/fight_reco_3DCNNmodel.pth\")\n",
        " \n",
        "print('TRAINING COMPLETE')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}